# Customer Churn Prediction Model Documentation

## 1. Introduction

This document provides a comprehensive overview of the Customer Churn Prediction Model project. The goal of this project is to predict customer churn using machine learning techniques, specifically leveraging PySpark for data processing and model training, MLflow for experiment tracking and auto-retraining, and ensemble methods for enhanced prediction accuracy. The system also incorporates ITIL-compliant logging and backup structures for robust operations.

## 2. Project Architecture

The project is structured into several key components:

*   **Data Ingestion & ETL (PySpark):** Handles loading raw customer data, cleaning, transformation, and feature engineering.
*   **Model Training & Evaluation (PySpark MLlib & Ensemble Methods):** Trains various machine learning models and combines them using ensemble techniques to improve predictive performance.
*   **MLflow Integration:** Manages the machine learning lifecycle, including experiment tracking, model versioning, and automated retraining.
*   **Logging & Monitoring (ITIL-compliant):** Provides structured logging for all system operations, ensuring traceability, security, and performance monitoring.
*   **Backup & Recovery:** Implements procedures for backing up critical data and models to ensure business continuity.

## 3. Setup and Installation

To set up and run this project, you will need the following:

### Prerequisites

*   Python 3.8+
*   Java 8+
*   Apache Spark 3.x
*   Pip (Python package installer)

### Installation Steps

1.  **Clone the repository:**
    ```bash
    git clone <repository_url>
    cd customer_churn_prediction
    ```

2.  **Install Python dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
    (Note: A `requirements.txt` file should be created with `pyspark`, `mlflow`, `pandas`, `numpy`, `schedule`)

3.  **Configure Spark:**
    Ensure your `SPARK_HOME` environment variable is set correctly and Spark is accessible.

4.  **Set up MLflow Tracking Server (Optional but Recommended):**
    For persistent tracking and model registry, set up an MLflow tracking server. You can run a local one:
    ```bash
    mlflow ui --backend-store-uri sqlite:///mlruns.db
    ```
    Then set the `MLFLOW_TRACKING_URI` environment variable:
    ```bash
    export MLFLOW_TRACKING_URI=http://127.0.0.1:5000
    ```

## 4. Data Preparation (ETL Pipeline)

The `src/etl_pipeline.py` script handles data loading, cleaning, and feature engineering.

### Usage

To run the ETL pipeline:

```bash
spark-submit src/etl_pipeline.py
```

This script will:

1.  Create a SparkSession.
2.  Load raw data from `/home/ubuntu/projects/customer_churn_prediction/data/telecom_churn.csv`.
3.  Clean the data (e.g., handle missing `TotalCharges`).
4.  Perform feature engineering (e.g., convert `SeniorCitizen` to categorical).
5.  Save the processed data as a Parquet file to `/home/ubuntu/projects/customer_churn_prediction/data/processed_churn_data.parquet`.

**Note:** A sample `telecom_churn.csv` is generated by `data/generate_sample_data.py` for demonstration purposes.

## 5. Model Training and Evaluation

The `src/model_training.py` script is responsible for training individual models (Logistic Regression, Random Forest, Gradient Boosting) and combining them into an ensemble model. It also evaluates their performance and logs results to MLflow.

### Usage

To train the models:

```bash
spark-submit src/model_training.py
```

This script will:

1.  Load the processed data.
2.  Prepare features using `StringIndexer`, `OneHotEncoder`, and `VectorAssembler`.
3.  Split data into training and testing sets.
4.  Train Logistic Regression, Random Forest, and Gradient Boosting models.
5.  Create an ensemble prediction using a simple voting mechanism.
6.  Evaluate individual and ensemble model performance (AUC, Accuracy).
7.  Log all metrics and models to MLflow.
8.  Save trained models to `/home/ubuntu/projects/customer_churn_prediction/models/`.

## 6. MLflow Auto-Retraining

The `src/mlflow_auto_retrain.py` script provides functionality for automated model retraining based on performance degradation, data drift, or a predefined schedule.

### Configuration

*   `performance_threshold`: Minimum acceptable AUC for the ensemble model (default: 0.85).
*   `retraining_interval_days`: How often to schedule retraining (default: 7 days).

### Usage

To run a manual check for retraining:

```bash
python3 src/mlflow_auto_retrain.py
```

To run the auto-retraining scheduler (will run in background):

```bash
python3 src/mlflow_auto_retrain.py --scheduler
```

This script will:

1.  Check the performance of the latest model in MLflow.
2.  (Optional) Check for data drift by comparing new data with reference data.
3.  Determine if retraining is needed based on performance degradation, data drift, or schedule.
4.  If retraining is triggered, it will re-run the `model_training.py` process.
5.  Log the new model and its performance to MLflow. If the new model performs better, it will be considered for promotion.

## 7. ITIL-Compliant Logging and Backup

The `src/itil_logging.py` module provides a robust logging and backup system designed with ITIL principles in mind.

### Key Features

*   **Structured Logging:** Logs are generated in JSON format, making them easy to parse and analyze.
*   **Categorized Logging:** Events are categorized into `operational`, `security`, `performance`, `error`, `audit`, and `change` logs.
*   **Log Rotation:** Log files are automatically rotated and compressed to manage disk space.
*   **Automated Backup:** Logs are periodically backed up to a designated directory (`logs/backups/`) and old backups are pruned based on retention policies.

### Usage

To integrate logging into your scripts, import `ModelOperationsLogger`:

```python
from src.itil_logging import ModelOperationsLogger

ops_logger = ModelOperationsLogger()

# Example usage:
ops_logger.log_model_training_start("ensemble_churn_model", {"n_estimators": 100})
ops_logger.log_error("ETL_FAILURE", details="Failed to load data from source")
```

## 8. Testing

Unit tests for the ETL pipeline are located in `tests/test_etl_pipeline.py`.

### Running Tests

```bash
python3 -m unittest tests/test_etl_pipeline.py
```

## 9. Future Enhancements

*   Implement more sophisticated ensemble techniques (e.g., stacking, blending).
*   Integrate with a feature store for better feature management.
*   Develop a dedicated model serving API for real-time predictions.
*   Enhance data drift detection with statistical tests (e.g., KS test, PSI).
*   Implement A/B testing for new model deployments.
*   Containerize the application using Docker for easier deployment.

## 10. License

This project is licensed under the MIT License - see the `LICENSE` file for details. (Note: A `LICENSE` file should be created.)


